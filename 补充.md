# 补充

# 数据结构和算法

## 行先列后

遍历数组时，外层循环应该先遍历行，内层循环遍历列。这样能充分利用空间的局部性原理，提升程序的性能。

原理：

* cpu 读取内存（速度慢）数据后，会将其放入高速缓存（速度快）当中，如果后来的计算再用到此数据，在缓存中能读到的话，就不必读内存了
* 缓存的最小存储单位是缓存行（cache line），一般是 64 bytes，一次读的数据少了不划算，因此最少读 64 bytes 填满一个缓存行，因此读入某个数据时也会读取其**临近的数据**，这就是所谓**空间局部性**

### 不用charAt

字符串的charAt方法获取字符的效率比较低，可以通过toCharArray方法获取字符数组，再从字符数组中获取单个字符，这样效率有比较大的提升。

# JDK

## 反射

#### 通过方法引用获取属性名

关键：获取到`SerializedLambda`对象，而获取此对象需要先获取`writeReplace`方法，而此方法只有该类实现了`Serializable`接口才会有，所以需要`SFunction`实现序列化接口。

补充：SerializedLambda是Java提供的关于lambda表达式的序列化方案。当需要对实现了Serializable接口的lambda表达式进行序列化时，Java虚拟机会将其转换成SerializedLambda对象，从而进行序列化操作。这个过程中，虚拟机会添加一个writeReplace()方法。SerializedLambda类存储了Lambda表达式的运行时信息，以确保Lambda表达式序列化的正确性和安全性。

~~~java
public class Lambda {
	public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException {
		SFunction<User, String> function = User::getUsername;
		Method method = function.getClass().getDeclaredMethod("writeReplace");
		method.setAccessible(true);
		Object name = method.invoke(function);
		SerializedLambda serializedLambda = (SerializedLambda) name;
		System.out.println(serializedLambda);
		String implMethodName = serializedLambda.getImplMethodName();
        // 获取get方法名
		System.out.println(implMethodName);
	}
}


@FunctionalInterface
interface SFunction<T, R> extends Serializable {
	R apply(T t);
}

class User {
	private String username;

	public String getUsername() {
		return username;
	}

	public void setUsername(String username) {
		this.username = username;
	}
}
~~~

# 数据库

## mysql

- 一次执行多条sql：前提条件是需要在url后面加上`&allowMultiQueries=true`
- 字段属性是逗号分隔的字符串，例如字段名`ancestors`，应该属性值是`3,400,23`，怎么查询出该字段属性值有`23`的记录。

~~~sql
SELECT * FROM sys_dept WHERE del_flag = 0 AND FIND_IN_SET(0,ancestors)
~~~

> `FIND_IN_SET(str, strlist)`函数：MySQL的字符串函数
>
> - 功能：在逗号分隔的字符串列表(`strList`)中查找指定的字符串(`str`)
> - 如果找到，返回大于0的位置索引（从1开始）；如果没找到，返回0

### 字段属性



# websocket

导入依赖：springboot版本-2.7.6

~~~xml
dependency>
<groupId>org.springframework.boot</groupId>
<artifactId>spring-boot-starter-websocket</artifactId>
</dependency>
~~~

配置类：

> `@ServerEndpoint`注解来定义WebSocket端点，使用了Java WebSocket API（JSR 356）的注解方式。这种方式无法在自定义ServerEndpointConfig.Configurator的实现类中直接依赖注入一些属性。
>
> 另一种使用方式是使用Spring的WebSocket支持（如`WebSocketConfigurer`、`TextWebSocketHandler`）

~~~kotlin
@Configuration
class WebSocketConfig {
	@Bean	//创建ServerEndpointExporter对象，作为bean放入容器，它可以自动注册使用了@ServerEndPoint注解的bean
	fun serverEndpointExporter(factory: LettuceConnectionFactory): ServerEndpointExporter {
		factory.validateConnection = true	//检查redis的连接是否断开，断开就重连（但检测和重连时间较长）
		return ServerEndpointExporter()
	}
}
~~~

EndPoint类：（不是单例的，建立一个连接就创建一个）

~~~kotlin
@ServerEndpoint("/chat/{username}")
@Component
class ChatEndpoint {

	companion object {
		// 用来存储每一个客户端对象对应的ChatEndpoint
		private val onlineUsers = ConcurrentHashMap<String, Session>()
		private lateinit var msgService: MsgService
	}

	private lateinit var username: String

	@Resource
	fun setMsgService(msgService: MsgService) {
		ChatEndpoint.msgService = msgService
	}

	@OnOpen    // 连接建立时被调用
	fun onOpen(session: Session, @PathParam("username") username: String) {
		onlineUsers[username] = session
		this.username = username
		val msgList = msgService.getList(username)
		//把用户之前不在线时暂存于redis的消息发送给用户
		msgList.forEach { session.basicRemote.sendText(it) }
		msgService.removeList(username)
	}

	@OnMessage    // 接收到客户端发送的数据时被调用
	fun onMessage(message: String, session: Session) {
		val toName = JsonUtils.getStringValue(message, Message::toName)
		//如果是心跳包
		if (toName == "ping") return LogUtils.info("接收到了一个心跳包：${session.requestURI}")
		val toSession = onlineUsers[toName]
		if (toSession == null) {    // 当前用户不在线，先把消息暂存于redis
			try {
				msgService.save(message, toName)
			} catch (e: Exception) {
				// 客户端需检查消息的fromName是否为error，为error代表消息发送失败
				val json = JsonUtils.toJson(Message(username, e.message ?: "发送失败", "error"))
				session.basicRemote.sendText(json)
				LogUtils.error(e.message, e)
			}
		} else {
			toSession.basicRemote.sendText(message)
		}
	}

	@OnClose    // 连接断开时被调用
	fun onClose(session: Session) {
		onlineUsers.remove(username)
	}

	@OnError
	fun onError(session: Session, t: Throwable) {
		LogUtils.error("socket -> ${t.message}", t)
	}
}
~~~

## token

携带token有两种方式，它不是传统的http请求，所以不能直接放到header里。

- 方法1：用query参数，在路径后面加`?token=xxx`
- 方法2：利用`Sec-WebSocket-Protocol`字段。

~~~js
const ws = new WebSocket("ws://localhost:32380/chat/lisi", ['token']);
~~~

> 这种配置方式使用的是Java WebSocket API（JSR 356），不方便给ServerEndpointConfig.Configurator的子类注入属性。

~~~kotlin
class EndpointConfigurator: ServerEndpointConfig.Configurator() {

	override fun modifyHandshake(sec: ServerEndpointConfig, request: HandshakeRequest, response: HandshakeResponse) {
		val tokens = request.headers["Sec-WebSocket-Protocol"]
		val token = tokens?.get(0)
		val template = ApplicationContextProvider.applicationContext.getBean(StringRedisTemplate::class.java)
		if (template.opsForValue().get("$TOKEN_PREFIX:$token") == null) {
			sec.userProperties["status"] = 401
		}
		//注意：Sec-WebSocket-Protocol该字段必须连同值原样返回，连接才能建立成功
		response.headers["Sec-WebSocket-Protocol"] = tokens
	}
}

@Component
class ApplicationContextProvider : ApplicationContextAware {
	companion object {
		lateinit var applicationContext: ApplicationContext
	}

	override fun setApplicationContext(applicationContext: ApplicationContext) {
		ApplicationContextProvider.applicationContext = applicationContext
	}
}

//并且：@ServerEndpoint("/chat/{username}", configurator = EndpointConfigurator::class)
//@onOpen: 
/*if (session.userProperties["status"] == 401) {
	session.basicRemote.sendText("token校验失败，将强制断开连接")
	return session.close()
}*/
~~~



# 算法

## DFA

Deterministic Finite Automaton（确定有穷自动机），可以用于检查文本中是否包含一些敏感词，效率高。

存储：需要一次性把敏感词都存储到map中；`isEnd`表示是否到了词尾。

判断是否包含敏感词：遍历文本的每个字，如果该字在map中，则从该字对应的value（map）中检查isEnd，为0继续检查下一个字是否在该value中，为1则返回true；某次检查到字不在map中，返回false。

例子：冰毒、大麻、大坏蛋。

~~~js
{
    "冰": {
        "毒":{
            "isEnd": 1
        },
        "isEnd": 0
    },
    "大": {
        "麻": {
            "isEnd": 1
        },
        "isEnd": 0,
        "坏": {
            "蛋": {
                "isEnd": 1
            },
            "isEnd": 0
        }
    }
}
~~~

~~~java
public class SensitiveWordUtil {

	public static Map<String, Object> dictionaryMap = new HashMap<>();

	public static void initMap(Collection<String> words) {
		if (words == null) {
			System.out.println("敏感词列表不能为空");
			return;
		}

		// map初始长度words.size()，整个字典库的入口字数(小于words.size()，因为不同的词可能会有相同的首字)
		Map<String, Object> map = new HashMap<>(words.size());
		// 遍历过程中当前层次的数据
		Map<String, Object> curMap = null;

		for (String word : words) {
			curMap = map;
			int len = word.length();
			for (int i = 0; i < len; i++) {
				// 遍历每个词的字
				String key = String.valueOf(word.charAt(i));
				// 当前字在当前层是否存在, 不存在则新建, 当前层数据指向下一个节点, 继续判断是否存在数据
				Map<String, Object> wordMap = (Map<String, Object>) curMap.get(key);
				if (wordMap == null) {
					// 每个节点存在两个数据: 下一个节点和isEnd(是否结束标志)
					wordMap = new HashMap<>(2);
					wordMap.put("isEnd", "0");
					curMap.put(key, wordMap);
				}
				curMap = wordMap;
				// 如果当前字是词的最后一个字，则将isEnd标志置1
				if (i == len - 1) {
					curMap.put("isEnd", "1");
				}
			}
		}
		dictionaryMap = map;
	}

	private static int checkWord(String text, int beginIndex) {
		if (dictionaryMap == null) {
			throw new RuntimeException("字典不能为空");
		}
		boolean isEnd = false;
		int wordLength = 0;
		Map<String, Object> curMap = dictionaryMap;
		int len = text.length();
		// 从文本的第beginIndex开始匹配
		for (int i = beginIndex; i < len; i++) {
			String key = String.valueOf(text.charAt(i));
			// 获取当前key的下一个节点
			curMap = (Map<String, Object>) curMap.get(key);
			if (curMap == null) {
				break;
			} else {
				wordLength++;
				if ("1".equals(curMap.get("isEnd"))) {
					isEnd = true;
				}
			}
		}
		if (!isEnd) {
			wordLength = 0;
		}
		return wordLength;
	}

	public static Map<String, Integer> matchWords(String text) {
		Map<String, Integer> wordMap = new HashMap<>();
		int len = text.length();
		for (int i = 0; i < len; i++) {
			int wordLength = checkWord(text, i);
			if (wordLength > 0) {
				String word = text.substring(i, i + wordLength);
				// 添加关键词匹配次数
				if (wordMap.containsKey(word)) {
					wordMap.put(word, wordMap.get(word) + 1);
				} else {
					wordMap.put(word, 1);
				}

				i += wordLength - 1;
			}
		}
		return wordMap;
	}
}
~~~

# 第三方库

## OCR

### Tess4J

封装了Google开源的OCR引擎：Tesseract-OCR。

可以继续其他语言的训练：https://tesseract-ocr.github.io/tessdoc/

~~~xml
<groupId>net.sourceforge.tess4j</groupId>   <artifactId>tess4j</artifactId>   <version>4.1.1</version>
<!--还需要导入相关语言的字体库-->
~~~

~~~java
//创建Tesseract对象
ITesseract tesseract = new Tesseract();
//设置字体库路径（不包含文件名）
tesseract.setDatapath(dataPath);
//中文识别（参数为字体库文件的名称，不需要后缀）
tesseract.setLanguage(language);
//执行ocr识别
String result = tesseract.doOCR(image);
//替换回车和tal键  使结果为一行
result = result.replaceAll("\\r|\\n", "-").replaceAll(" ", "");
return result;
~~~

# 设计模式

## DDD

参考文章：

- [还在搞三层架构？了解下 DDD 分层架构的三种模式吧 ！ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU0OTE4MzYzMw==&mid=2247560567&idx=2&sn=2236a4244fde4a859b54a86b172ccb48&chksm=fbb06489ccc7ed9f7f8a086347a2d71fa04a33dc3335032f1d2a979ea1ba64b86e097bb32fed&scene=27)
- [一文读懂DDD，秒懂！ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzU0OTE4MzYzMw==&mid=2247540664&idx=2&sn=1b3d3718f389563f75ae5592600eac4b&chksm=fbb1d646ccc65f503ad99dfb54794111964a3b1b59fc5788fe5d38de1fcc3aad9ca9fed7fae2&scene=27)
- [DDD 架构 | 小傅哥 bugstack 虫洞栈](https://bugstack.cn/md/road-map/ddd.html)

### 概念

DDD（Domain DrivenDesign，领域驱动设计）采用的是松散分层架构，层间关系不那么严格。每层都可能使用它下面所有层的服务，而不仅仅是下一层的服务。每层都可能是半透明的，这意味着有些服务只对上一层可见，而有些服务对上面的所有层都可见。

> 严格分层架构：某层只能与直接位于的下层发生耦合。
>
> 松散分层架构：允许上层与任意下层发生耦合。

![图片](https://mmbiz.qpic.cn/mmbiz_png/sXFqMxQoVLESpJibWtYnlHsuuI2wOYE4gH4zTYicZIwYwpa46cW4g4apHxCD9IehxDhc6V37kDSnsia8SQHKIhZ4Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

分层的作用，从上往下：

- **用户交互层**：web 请求，rpc 请求，mq 消息等外部输入均被视为外部输入的请求，可能修改到内部的业务数据。
- **业务应用层**：与 MVC 中的 service 不同的不是，service 中存储着大量业务逻辑。但在应用服务的实现中，它负责编排、转发、校验等。
- **领域层**：或称为模型层，系统的核心，负责表达业务概念，业务状态信息以及业务规则。即包含了该领域所有复杂的业务知识抽象和规则定义。该层主要精力要放在领域对象分析上，可以从实体，值对象，聚合（聚合根），领域服务，领域事件，仓储，工厂等方面入手。
- **基础设施层**：主要有 2 方面内容，一是为领域模型提供持久化机制，当软件需要持久化能力时候才需要进行规划；一是对其他层提供通用的技术支持能力，如消息通信，通用工具，配置等的实现。

UL（Ubiquitous Language，通用语言）是团队共享的语言，是DDD中最具威力的特性之一。不管你在团队中的角色如何，只要你是团队的一员，你都将使用UL。由于UL的重要性，所以需要让每个概念在各自的上下文中是清晰无歧义的，于是DDD在战略设计上提出了模式BC（BoundedContext，限界上下文）。UL和BC同时构成了DDD的两大支柱，并且它们是相辅相成的，即UL都有其确定的上下文含义，而BC中的每个概念都有唯一的含义。

### MVC问题

简单、容易、好理解，是 MVC 架构的特点，但也正因为简单的分层逻辑，在适配较复杂的场景并且需要长周期的维护时，代码的迭代成本就会越来越高。

MVC 分层结构是一种贫血模型设计，它将”状态“和”行为“分离到不同的包结构中进行开发使用。domain 里写 po、vo、enum 对象，service 里写功能逻辑实现。也正因为 MVC 结构没有太多的约束，让前期的交付速度非常快。但随着系统工程的长期迭代，贫血对象开始被众多 serivice 交叉使用，而 service 服务也是相互调用。这样缺少一个上下文关系的开发方式，让长期迭代的 MVC 工程逐步腐化到严重腐化。

**MVC 工程的腐化根本**，就在于对象、服务、组件的交叉混乱使用。时间越长，腐化的越严重。

### MVC->DDD

经过实践验证，不需要太高成本，MVC 就可以天然的向 DDD 工程分层的模型结构转变。重点是不改变原有的工程模块的依赖关系，将贫血的 domain 对象层，设计为充血的结构。**对于 domain 原本在 MVC 分层结构中，就是一个被依赖层，恰好可以与其他层做依赖倒置的设计方案处理**。具体如图所示：

![img](https://bugstack.cn/images/roadmap/tutorial/road-map-ddd-04.png?raw=true)

左侧是我们常见的 MVC 分层结构，右侧是给大家上文讲解过的 DDD 分层结构。从 MVC 到 DDD 的映射，使用了相同颜色进行标注。之后我来介绍一些细节：

在 MVC 分层结构中，所有的逻辑都集中在 service 层，也是文中提到的腐化最严重的层，要治理的也是这一层。所以首先我们要将 service 里的功能进行拆解。

1. service 中具备领域特性的服务实现，抽离到原本贫血模型的 domain 中。在 domain 分层中添加 xxx、yyy、zzz 分层领域包，分别实现不同功能。**注意每个分层领域包内都具备完整的 DDD 领域服务内所需的模块**
2. service 中的基础功能组件，如：缓存Redis、配置中心等，迁移到 dao 层。这里我们把 dao 层看做为基础设施层。它与 domain 领域层的调用关系，为依赖倒置。也就是 domain 层定义接口，dao 层依赖于 domain 定义的接口，做依赖倒置实现接口。
3. service 本身最后被当做 application/case 层，来调用 domain 层做服务的编排处理。

因为恰好，MVC 分层结构中，也是 service 和 dao 依赖于 domain，这和 DDD 分层结构是一致的。所以经过这样的映射拆分代码实现调用结构后，并不会让工程结构发生变化。那么只要工程结构不发生变化，我们的改造成本就只剩下代码编写风格和旧代码迁移成本。

MVC 分层结构中的 export 层是 RPC 接口定义层，由 web 层实现。web 是对 service 的调用。也就是 DDD 分层结构中调用 application 编排好的服务。这部分无需改动。**但如果你原有工程把 domain 也暴露出去了，则需要把对应的包迁移到 export** 因为 domain 包有太多的核心对象和属性，还包括数据库持久化对象。这些都不应该被暴露。

MVC 分层中，因为有需要对外部 RPC 接口的调用，所以会单独有一层 RPC 来封装其他服务的接口。这一层被 domain 领域层使用，可以定义 adapter 适配器接口，通过依赖倒置，在 rpc 层实现 domain 层定义的调用接口。

此外 dao 层，在 MVC 结构中原本是比较单一的。但经过改造后会需要把基础的 Redis 使用、配置中使用，都迁移到 dao 层。因为原本在 service 层的话，domain 层是调用不到的这些基础服务的，而且也不符合服务功能边界的划分。

**综上**，就是从 MVC 到 DDD 重构架构的拆解实现方案。这是一种最低成本的最佳实施策略，完全可以保证 MVC 的结构，又可以应用上 DDD 的架构分层优势。也能运用 DDD 领域驱动设计思想，重构旧代码，增加可维护性。

### 模式

#### 四层架构

Eric Evans在《领域驱动设计－软件核心复杂性应对之道》这本书中提出了传统的四层架构模式，如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/Baq5lYpIw7WJcia0txlkZb8ibUxRc9PzLMrobBarklIuZmVeD75XG6yFDEF2vODkkFUeAraR2FL6FZia5GKa9k0gg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 五层架构

ames O. Coplien和Trygve Reenskaug在2009年发表了一篇论文《DCI架构：面向对象编程的新构想》，标志着DCI架构模式的诞生。DCI目前广泛被看作是对DDD的一种发展和补充。

> James O.Coplien也是MVC架构模式的创造者（年轻时）

引入DCI后，DDD四层架构模式中的Domain层变薄了，以前Domain层对应DCI中的三层，而现在：

1. Domain层只保留了DCI中的Data层和Interaction层，我们在实践中通常将这两层使用目录隔离，即通过两个目录object和role来分离层Data和Interaction。

![图片](https://mmbiz.qpic.cn/mmbiz_png/Baq5lYpIw7WJcia0txlkZb8ibUxRc9PzLMibPDJQ1n3P364WCU2W2lNapegQzW783EZMFSticjQda6LPyaictSiaGN6Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)object-role-dir.png

2. DCI中的Context层从Domain层上移变成Context层。
	因此，DDD分层架构模式就变成了五层，如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/Baq5lYpIw7WJcia0txlkZb8ibUxRc9PzLMe7nd1k8zUw0QoOuv5JqhkU0LzQXktAyGv2B3X7peyB9KeeStBA0Ypw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

##### 六层

在面向控制面或管理面且消息交互比较多的系统中，DDD分层架构模式就变成了六层，如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/Baq5lYpIw7WJcia0txlkZb8ibUxRc9PzLM8PAWpb6iceYVluKa5rhOQqv3DkhKKe3NFfvIuNh64P1KTDtqWfxxy7A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

DDD六层架构可以看做是DDD五层架构在特定领域的变体，我们统称为DDD五层架构，而DDD五层架构与传统的四层架构类似，都是**限定型松散分层架构** 。

#### 六边形架构

有一种方法可以改进分层架构，即依赖倒置原则(Dependency Inversion Principle,DIP)，它通过改变不同层之间的依赖关系达到改进目的。

根据该定义，DDD分层架构中的低层组件应该依赖于高层组件提供的接口，即无论高层还是低层都依赖于抽象，整个分层架构好像被推平了。如果我们把分层架构推平，再向其中加入一些对称性，就会出现一种具有对称性特征的架构风格，即六边形架构。六边形架构是Alistair Cockburn在2005年提出的，在这种架构中，不同的客户通过“平等”的方式与系统交互。需要新的客户吗？不是问题。只需要添加一个新的适配器将客户输入转化成能被系统API所理解的参数就行。同时，对于每种特定的输出，都有一个新建的适配器负责完成相应的转化功能。

六边形架构也称为端口与适配器，如下图所示：

![图片](https://mmbiz.qpic.cn/mmbiz_png/Baq5lYpIw7WJcia0txlkZb8ibUxRc9PzLM0Z6jsjFMiaTyzO1MUNNVvP30PCuKjiatvFyicdvC8sjD8qIZKCBjdLq5Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

尽管六边形架构模式已经很好，但是没有最好只有更好，演变没有尽头。在六边形架构模式提出后的这些年，又依次衍生出三种六边形架构模式的变体：

- Jeffrey Palermo在2008年提出了  洋葱架构  ，六边形架构是洋葱架构的一个超集。
- Robert C. Martin在2012年提出了  干净架构  （Clean Architecture），这是六边形架构的一个变体。
- Russ Miles在2013年提出了  Life Preserver  设计，这是一种基于六边形架构的设计。

### 具体结构

#### 四层

如下是 DDD 架构的一种分层结构，也可以有其他种方式，核心的重点在于适合你所在场景的业务开发。（做了简化处理）

![img](https://bugstack.cn/images/roadmap/tutorial/road-map-230624-03.png?raw=true)

- **接口定义 - xfg-frame-api**：因为微服务中引用的 RPC 需要对外提供接口的描述信息，也就是调用方在使用的时候，需要引入 Jar 包，让调用方好能依赖接口的定义做代理。
- **应用封装 - xfg-frame-app**：这是应用启动和配置的一层，如一些 aop 切面或者 config 配置，以及打包镜像都是在这一层处理。你可以把它理解为专门为了启动服务而存在的。
- **领域封装 - xfg-frame-domain**：领域模型服务，是一个非常重要的模块。无论怎么做DDD的分层架构，domain 都是肯定存在的。在一层中会有一个个细分的领域服务，在每个服务包中会有【模型、仓库、服务】这样3部分。
- **仓储服务 - xfg-frame-infrastructure**：基础层依赖于 domain 领域层，因为在 domain 层定义了仓储接口需要在基础层实现。这是依赖倒置的一种设计方式。
- **领域封装 - xfg-frame-trigger**：触发器层，一般也被叫做 adapter 适配器层。用于提供接口实现、消息接收、任务执行等。所以对于这样的操作，小傅哥把它叫做触发器层。
- **类型定义 - xfg-frame-types**：通用类型定义层，在我们的系统开发中，会有很多类型的定义，包括；基本的 Response、Constants 和枚举。它会被其他的层进行引用使用。
- **领域编排【可选】 - xfg-frame-case**：领域编排层，一般对于较大且复杂的的项目，为了更好的防腐和提供通用的服务，一般会添加 case/application 层，用于对 domain 领域的逻辑进行封装组合处理。

# 技术

## 多租户

对于数据库存储数据有三种方案：

- 共享数据共享数据表：每个表需要增加租户id区分是哪个租户的数据
	- 特点：成本低、复杂度高、隔离性差、数据备份和恢复最困难
- 共享数据库独立schema：每个租户一个schema
	- 特点：成本低、复杂度一般、隔离性一般、数据恢复困难
	- schema在mysql中是database，在oracle中是用户（表空间隔离）
- 独立数据库：每个租户一个数据库
	- 特点：成本高、复杂度一般、隔离性最好、数据恢复简单

## 发票文件解析

参考文章：[JAVA识别PDF和OFD电子发票并解析为java对象_电子发票pdf二维码识别-CSDN博客](https://blog.csdn.net/Alex_81D/article/details/129045748)

使用库：PDF-`pdfbox`、OFD-`ofdrw`

- 依赖

~~~xml
<!--PDFBox-->
<dependency>
  <groupId>org.apache.pdfbox</groupId>
  <artifactId>pdfbox</artifactId>
  <version>2.0.26</version>
</dependency>
<!--ofdrw-->
<dependency>
  <groupId>org.ofdrw</groupId>
  <artifactId>ofdrw-full</artifactId>
  <version>2.3.6</version>
</dependency>
~~~

- PDF解析示例

~~~java
public static final Pattern HOTEL_MONEY_PATTERN = Pattern.compile("价税合计\\(大写\\) (?<amountString>\\S*) \\(小写\\)¥?(?<amount>\\S*)");
public static final Pattern HOTEL_NAME_PATTERN = Pattern.compile("\\s*(.+)\\s*备");

public static Invoice pdfInvoiceExtract(File file) {
  Invoice invoice = new Invoice();
  try (PDDocument document = PDDocument.load(file)) {
    PDFTextStripper stripper = new PDFTextStripper();
    stripper.setSortByPosition(true);
    String text = stripper.getText(document);
    text = text.replaceAll("（", "(").replaceAll("）", ")")
      .replaceAll("￥", "¥").replaceAll("：", ":")
      .replaceAll("；", " ").replaceAll(" {2}", " ");
    Matcher matcher = HOTEL_MONEY_PATTERN.matcher(text);
    if (matcher.find()) {
      invoice.setTotalMoney(new BigDecimal(matcher.group("amount")));
    }
    matcher = HOTEL_NAME_PATTERN.matcher(text);
    if (matcher.find()) {
      invoice.setRemark(matcher.group(1));
    }
    invoice.setFile(file);
  } catch (Exception e) {
    log.error("识别发票失败，发票文件：{}, 报错信息：{}", file.getName(), e.getMessage(), e);
  }
  return invoice;
}
~~~

- OFD解析示例

~~~java
public static Invoice ofdInvoiceExtract(File file) {
  Invoice invoice = new Invoice();
  try (OFDReader reader = new OFDReader(file.getPath())) {
    Page page = reader.getPage(1);
    CT_Layer layer = page.getContent().getLayers().get(0);
    // 方法1：根据ID获取元素（ID查看方式：将ofd文件解压缩后，找到content.xml文件打开即可）
    String totalMoneyStr = layer.elementByID("1000").element("TextCode").getText();
    // 方法2：自己进行循环查找（有些ofd文件里ID相同的元素会有多个，而ofdrw没有提供elementsByID方法，只能循环里获取）
    for (Node node : layer.content()) {
      if (!(node instanceof Element)) continue;
      Element textObject = (Element) node;
      if (!"TextObject".equals(textObject.getName())) continue;
      String id = textObject.attributeValue("ID");
      if ("1000".equals(id)) {
        totalMoneyStr = textObject.element("TextCode").getText();
      }
    }
    // 方法3：content.xml文件里相关node是有位置信息的，也可以通过指定坐标来提取矩形框里的内容
  } catch (Exception e) {
    log.error("识别发票失败，发票文件：{}, 报错信息：{}", file.getName(), e.getMessage(), e);
  }
  return invoice;
}
~~~

## 邮箱

| **特性**       | **SMTP**   | **IMAP**           | **POP3**           |
| -------------- | ---------- | ------------------ | ------------------ |
| **主要功能**   | 发送邮件   | 接收并同步邮件     | 下载邮件到本地     |
| **数据存储**   | 不存储邮件 | 邮件保留在服务器   | 默认从服务器删除   |
| **多设备同步** | 不适用     | 支持（实时同步）   | 不支持（默认）     |
| **典型端口**   | 25/465/587 | 143/993            | 110/995            |
| **适用场景**   | 邮件发送   | 现代多设备邮件管理 | 旧版单设备邮件访问 |

1. 依赖

~~~xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-mail</artifactId>
</dependency>
~~~

2. 相关配置（用126邮箱示例）

~~~yaml
spring:
  mail:
    # 发送邮件配置
    host: smtp.126.com
    password: # 不是邮箱登录密码，是授权密码
    username: ningbiluoer@126.com
    port: 465
    default-encoding: UTF-8
    protocol: smtp
    properties:
      mail.smtp.auth: true
      mail.smtp.starttls.enable: true
      mail.smtp.starttls.required: true
      mail.smtp.socketFactory.port: 465
      mail.smtp.socketFactory.class: javax.net.ssl.SSLSocketFactory
      mail.smtp.socketFactory.fallback: false
    # 接收邮件配置
    imap:
      host: imap.126.com
      port: 993
~~~

3. IMAP配置类

~~~java
@Configuration
public class MailReceiverConfig {
    @Value("${spring.mail.username}")
    private String username;

    @Value("${spring.mail.password}")
    private String password;

    @Value("${spring.mail.imap.host}")
    private String imapHost;

    @Value("${spring.mail.imap.port:993}")
    private String imapPort;

    @Bean
    public Store mailStore() throws MessagingException {
        Properties props = new Properties();
        props.put("mail.store.protocol", "imap");
        props.put("mail.imap.host", imapHost);
        props.put("mail.imap.port", imapPort);
        props.put("mail.imap.ssl.enable", "true");  // 启用 SSL
        props.put("mail.imap.auth", "true");       // 启用认证

        // 报错：A3 NO SELECT Unsafe Login. Please contact kefu@188.com for help
        // 这部分就是解决异常的关键所在，设置IAMP ID信息
        Map<String, String> iam = new HashMap<>();
        // 带上IMAP ID信息，由key和value组成，例如name，version，vendor，support-email等。
        // 这个value的值随便写就行
        iam.put("name", "biluo");
        iam.put("version", "1.0.0");
        iam.put("vendor", "myclient");
        iam.put("support-email", "ningbiluoer@126.com");

        Session session = Session.getInstance(props);
        IMAPStore store = (IMAPStore) session.getStore("imap");
        store.connect(username, password);
        store.id(iam);
        return store;
    }
}
~~~

4. service类

~~~java
public interface MailService  {
    /**
     * 发送邮件
     */
    boolean sendMail(String to, String subject, String text);

    /**
     * 接收邮件
     */
    List<Message> receiveMail();

    /**
     * 接收未读邮件
     */
    List<Message> receiveUnreadMail();

    /**
     * 接收指定发件人的未读邮件
     */
    List<Message> receiveUnreadMailFrom(String from, Consumer<List<Message>> cb);
}
~~~

5. service实现类

~~~java
@Service
@RequiredArgsConstructor
@Slf4j
public class MailServiceImpl implements MailService {

    private final JavaMailSender mailSender;
    private final Store mailStore;

    @Value("${spring.mail.username}")
    private String username;

    @Override
    public boolean sendMail(String to, String subject, String text) {
        SimpleMailMessage msg = new SimpleMailMessage();
        msg.setFrom(username);
        msg.setTo(to);
        msg.setSubject(subject);
        msg.setText(text);
        try {
            mailSender.send(msg);
        } catch (MailException e) {
            log.error("发送邮件失败：{}", e.getMessage(), e);
            return false;
        }
        return true;
    }

    @Override
    public List<Message> receiveMail() {
        List<Message> messages = new ArrayList<>();
        Folder inbox = null;
        try {
            inbox = mailStore.getFolder("INBOX");
            inbox.open(Folder.READ_ONLY);
            messages = Arrays.asList(inbox.getMessages());
        } catch (Exception e) {
            log.error("获取邮箱失败：{}", e.getMessage(), e);
        } finally {
            if (inbox != null && inbox.isOpen()) {
                try {
                    inbox.close();
                } catch (MessagingException e) {
                    log.error("关闭邮箱失败：{}", e.getMessage(), e);
                }
            }
        }
        return messages;
    }

    @Override
    public List<Message> receiveUnreadMail() {
        List<Message> unreadMsgs = new ArrayList<>();
        Folder inbox = null;
        try {
            // 获取收件箱文件夹并以读写模式打开
            inbox = mailStore.getFolder("INBOX");
            inbox.open(Folder.READ_WRITE);
            // 搜索所有未读邮件（即未设置SEEN标志的邮件）
            Message[] messages = inbox.search(new FlagTerm(new Flags(Flags.Flag.SEEN), false));
            unreadMsgs = Arrays.asList(messages);
        } catch (MessagingException e) {
            log.error("获取邮箱失败：{}", e.getMessage(), e);
        } catch (Exception e) {
            log.error("获取邮箱时发生未知错误：{}", e.getMessage(), e);
        } finally {
            // 确保邮箱文件夹正确关闭
            if (inbox != null && inbox.isOpen()) {
                try {
                    inbox.close();
                } catch (MessagingException e) {
                    log.error("关闭邮箱失败：{}", e.getMessage(), e);
                }
            }
        }
        return unreadMsgs;
    }

    @Override
    public List<Message> receiveUnreadMailFrom(String from, Consumer<List<Message>> cb) {
        List<Message> unreadMsgs = new ArrayList<>();
        Folder inbox = null;
        try {
            // 获取收件箱文件夹并以读写模式打开
            inbox = mailStore.getFolder("INBOX");
            //inbox = mailStore.getFolder("Trash");   // 获取垃圾箱文件夹
            inbox.open(Folder.READ_WRITE);
            // 搜索所有未读邮件（即未设置SEEN标志的邮件）
            FlagTerm unreadTerm = new FlagTerm(new Flags(Flags.Flag.SEEN), false);
            // 搜索指定发件人的邮件
            FromTerm fromTerm = new FromTerm(new InternetAddress(from));
          	// 若收件人又多个
          	/*
          	List<FromTerm> fromTermList = new ArrayList<>();
            for (String sender : senderList) {
                FromTerm fromTerm = new FromTerm(new InternetAddress(sender));
                fromTermList.add(fromTerm);
            }
            OrTerm orTerm = new OrTerm(fromTermList.toArray(new SearchTerm[]{}));
            AndTerm combinedTerm = new AndTerm(unreadTerm, orTerm);
          	*/
            // 将两个搜索条件组合成一个AndTerm
            AndTerm combinedTerm = new AndTerm(unreadTerm, fromTerm);
            // 搜索邮件
            Message[] messages = inbox.search(fromTerm);
            unreadMsgs = Arrays.asList(messages);

            cb.accept(unreadMsgs);
        } catch (MessagingException e) {
            log.error("获取邮箱失败：{}", e.getMessage(), e);
        } catch (Exception e) {
            log.error("获取邮箱时发生未知错误：{}", e.getMessage(), e);
        } finally {
            // 确保邮箱文件夹正确关闭
            if (inbox != null && inbox.isOpen()) {
                try {
                    inbox.close();
                } catch (MessagingException e) {
                    log.error("关闭邮箱失败：{}", e.getMessage(), e);
                }
            }
        }
        return unreadMsgs;
    }
}
~~~



## 权限

- 数据权限：
  - 方法1：通过 AOP+自定义注解给 SQL 语句加上过滤条件，从而根据不同角色/用户实现数据过滤的效果。 
  - 方法2：如果使用了mybatis，可以自定义mybatis拦截器为执行的sql添加过滤条件，类似于pageHelper的分页插件。
- 菜单权限：前端通过后端返回的权限列表动态渲染页面菜单，从而实现不同用户登录时，看到不同的菜单。 
- 功能/操作权限：数据库中的功能权限表中存储了权限和其对应的标识符等数据，使用 SpringSecurity 在用户登录时获取该用户的功能权限列表，并通过其提供的权限注解给具体的 API 接口加上权限校验，从而让用户无法越 权操作；前端通过 Vue 的自定义指令和后端返回的功能权限列表实现按钮的动态渲染，让没有相关操作权限的用户无法看到相应的操作按钮。

### 数据权限

#### mybatis拦截器

示例：

1. 工具类

~~~java
public class DataFilter {
    /**
     * sql条件子句
     */
    protected static final ThreadLocal<String> LOCAL_CLAUSE = new ThreadLocal<>();

    protected static void setClause(String clause) {
        LOCAL_CLAUSE.set(clause);
    }

    public static String getClause() {
        return LOCAL_CLAUSE.get();
    }

    public static void clear() {
        LOCAL_CLAUSE.remove();
    }

    /**
     * 用指定的sql子句进行数据过滤
     * <p>使用此方法需要被执行的sql中带有 WHERE 子句，例如：WHERE 1 = 1</p>
     * @param clause sql子句
     */
    public static void startFilter(String clause) {
        setClause(clause);
    }
}
~~~

2. 拦截器

~~~java
@Intercepts({
        // 拦截Executor的query方法（不带CacheKey和BoundSql参数）
        @Signature(type = Executor.class, method = "query", args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class}),
        // 拦截Executor的query方法（带CacheKey和BoundSql参数）
        @Signature(type = Executor.class, method = "query", args = {MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class}),
        // 拦截Executor的update方法（包括update、insert、delete语句）方法
        @Signature(type = Executor.class, method = "update", args = {MappedStatement.class, Object.class}),
})
public class DataFilterInterceptor implements Interceptor {
    public DataFilterInterceptor() {
        log.info("数据过滤拦截器初始化成功");
    }

    private static final Logger log = LoggerFactory.getLogger(DataFilterInterceptor.class);

    /**
     * 拦截方法，在SQL执行前进行处理
     */
    @Override
    public Object intercept(Invocation invocation) throws Throwable {
        // 获取数据过滤条件
        String clause = DataFilter.getClause();
        // 如果没有过滤条件，直接执行原SQL
        if (clause == null) {
            return invocation.proceed();
        }
        log.info("数据过滤拦截器-附加sql子句：{}", clause);
        
        // 1.获取原始sql
        Object[] args = invocation.getArgs();
        MappedStatement ms = (MappedStatement) args[0];
        BoundSql boundSql;
        // 根据参数数量判断是哪种query方法
        if (args.length == 6) {
            // 带CacheKey和BoundSql的query方法
            boundSql = (BoundSql) args[5];
        } else {
            // 普通query或update方法
            boundSql = ms.getBoundSql(args[1]);
        }
        String originalSql = boundSql.getSql();
        
        // 2.改写sql，添加数据过滤条件
        String newSql = appendDataFilter(originalSql, clause);
        
        // 3.替换SQL
        BoundSql newBoundSql = new BoundSql(ms.getConfiguration(), newSql,
                boundSql.getParameterMappings(), boundSql.getParameterObject());
        if (args.length == 6) {
            // 更新带CacheKey和BoundSql参数的query方法中的BoundSql
            args[5] = newBoundSql;
        } else {
            // 替换普通query或update方法中的MappedStatement
            MappedStatement newMs = copyFromMappedStatement(ms, new BoundSqlSqlSource(newBoundSql));
            args[0] = newMs;
        }

        // 4.执行方法
        return invocation.proceed();
        // 注意：清理ThreadLocal数据不能放在这，因为使用分页拦截器时会执行count和select两个语句，
        // 清除数据后会导致只有count语句会被加上过滤条件
    }

    /**
     * 在原始SQL中添加数据过滤条件
     */
    private String appendDataFilter(String originalSql, String clause) {
        String lowerSql = originalSql.toLowerCase();
        // 查找order by 和 limit 的位置
        int orderByIndex = lowerSql.lastIndexOf("order by");
        int limitIndex = lowerSql.lastIndexOf("limit");

        if (orderByIndex != -1) {
            // 存在order by，将条件插入到 order by前
            String beforeOrderBy = originalSql.substring(0, orderByIndex);
            String afterOrderBy = originalSql.substring(orderByIndex);
            return beforeOrderBy + " AND" + clause + " " + afterOrderBy;
        } else {
            // 不存在order by，存在limit，将条件插入到 limit 前
            if (limitIndex != -1) {
                String beforeLimit = originalSql.substring(0, limitIndex);
                String afterLimit = originalSql.substring(limitIndex);
                return beforeLimit + " AND" + clause + " " + afterLimit;
            }
            // 不存在order by，不存在limit，将条件插入到sql的末尾
            return originalSql + " AND" + clause;
        }
    }

    /**
     * 复制 MappedStatement 并替换 BoundSql
     */
    private MappedStatement copyFromMappedStatement(MappedStatement ms, SqlSource newSqlSource) {
        MappedStatement.Builder builder = new MappedStatement.Builder(
                ms.getConfiguration(),
                ms.getId(),
                newSqlSource,
                ms.getSqlCommandType()
        );
        // 复制其他属性（如 resultMaps、parameterMap 等）
        builder.resource(ms.getResource());
        builder.fetchSize(ms.getFetchSize());
        builder.statementType(ms.getStatementType());
        builder.keyGenerator(ms.getKeyGenerator());
        builder.timeout(ms.getTimeout());
        builder.parameterMap(ms.getParameterMap());
        builder.resultMaps(ms.getResultMaps());
        builder.resultSetType(ms.getResultSetType());
        builder.cache(ms.getCache());
        builder.flushCacheRequired(ms.isFlushCacheRequired());
        builder.useCache(ms.isUseCache());
        return builder.build();
    }

    /**
     * 自定义 SqlSource，用于动态 SQL
     */
    public static class BoundSqlSqlSource implements SqlSource {
        private final BoundSql boundSql;

        public BoundSqlSqlSource(BoundSql boundSql) {
            this.boundSql = boundSql;
        }

        @Override
        public BoundSql getBoundSql(Object parameterObject) {
            return boundSql;
        }
    }
}
~~~

3. 注册拦截器

~~~java
@Configuration
public class MyBatisConfig {
    @Bean
    public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {
        SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();
        sessionFactory.setDataSource(dataSource);
        sessionFactory.setPlugins(new DataFilterInterceptor());
        return sessionFactory.getObject();
    }
}

// mp中
@Configuration
public class MyBatisPlusConfig {
    @Bean
    public DataFilterInterceptor dataFilterInterceptor() {
        return new DataFilterInterceptor();
    }
}
~~~

4. 使用

~~~java
@GetMapping("/list")
public R<List<HotelOrderVo>> list(HotelOrderReqDto dto) {
  List<String> codeList = sysDeptService.selectCodeList(getDeptId()).stream()
    .map(code -> "'" + code + "'")
    .collect(Collectors.toList());
  DataFilter.startFilter(" dept_id IN (" + StringUtils.join(codeList, ",") + ")");
	//PageUtils.startPage();
  List<HotelOrderVo> list = hotelOrderService.list(dto);
  DataFilter.clear();
  // 使用了分页拦截器后返回的list实际是继承了List的Page对象
  return R.ok(list);
}
~~~

#### 切面

示例：

1. 数据权限过滤注解

~~~java
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface DataFilter {

    String FILTER_TYPE_EQ = "=";
    String FILTER_TYPE_IN = "IN";

    /**
     * 表别名
     */
    String alias() default "";

    /**
     * 过滤字段
     */
    String field() default "";

    /**
     * 过滤类型
     */
    String type() default FILTER_TYPE_IN;
}
~~~

2. 基础查询类：想要使用数据过滤的方法，其参数需要继承该类。

~~~java
@Data
public class Query {
    /**
     * 查询条件子句
     */
    @JsonIgnore
    private String clause;

    /**
     * 查询条件参数
     */
    @JsonIgnore
    private String filterParams;
}
~~~

3. 切面类

~~~java
@Aspect
@Component
public class DataFilterAspect {
    private final Logger log = LoggerFactory.getLogger(DataFilterAspect.class);

    @Before("@annotation(dataFilter)")
    public void doBefore(JoinPoint point, DataFilter dataFilter) {
        // 1.获取调用的方法参数
        Object arg = point.getArgs()[0];
        if (!(arg instanceof Query)) {
            log.warn("调用方法[{}], 参数不是Query对象", point.getSignature().getName());
            return;
        }
        Query query = (Query) arg;

        // 获取当前的用户
        LoginUser loginUser = SecurityUtils.getLoginUser();
        SysUser user = loginUser.getUser();
        if (user.isAdmin()) {
            // 如果是超级管理员，则不过滤数据
            query.setClause(null);
            return;
        }

        // 2.获取数据过滤注解的参数
        String alias = dataFilter.alias();
        String field = dataFilter.field();
        String type = dataFilter.type();
        if (StringUtils.isEmpty(field)) {
            log.warn("调用方法[{}], 数据过滤注解的field参数为空", point.getSignature().getName());
            return;
        }
        if (StringUtils.isEmpty(type)) {
            log.warn("调用方法[{}], 数据过滤注解的type参数为空", point.getSignature().getName());
            return;
        }

        // 3.设置查询sql子句
        if (StringUtils.isNotEmpty(query.getClause())) {
            return;
        }
        String clause;
        if (StringUtils.isNotEmpty(query.getFilterParams())) {
            if (StringUtils.isNotEmpty(alias)) {
                clause = StringUtils.format("{}.{} {} {}", alias, field, type, query.getFilterParams());
            } else {
                clause = StringUtils.format("{} {} {}", field, type, query.getFilterParams());
            }
            query.setClause(clause);
            return;
        }

        if (StringUtils.isNotEmpty(alias)) {
            clause = StringUtils.format("{}.{} IN ( SELECT company_code FROM sys_user_company WHERE user_id = {} )", alias, field, user.getUserId());
        } else {
            clause = StringUtils.format("{} IN ( SELECT company_code FROM sys_user_company WHERE user_id = {} )", field, user.getUserId());
        }
        query.setClause(clause);
    }
}
~~~

4. 使用

   1. mapper.xml 里的sql需要加入如下内容：

   ~~~xml
   <if test="query.clause != null and query.clause != ''">
     AND ${query.clause}
   </if>
   ~~~

   2. mapper类方法上加上注解：`@DataFilter(alias = "t1", field = "company_code")`

# spring相关

## 获取request

~~~java
ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
		HttpServletRequest request = requestAttributes.getRequest();
~~~

## map依赖注入

当对`Map<String, 具体类型>`的属性进行依赖注入时，Spring会自动创建一个Map，并且把符合Map的value类型的bean放到Map中，key为该bean的name。

例如以下代码：（为解耦登录的方式，使用策略+工厂模式）

~~~java
// 登录策略接口
public interface LoginStrategy {
	UserDetails doLogin(String username);
}

// 具体的登录策略类
@Service(AuthConstants.LOGIN_TYPE_SYS)
@AllArgsConstructor
public class SysUserLoginStrategy implements LoginStrategy {
	private final LoginSysUserMapper loginSysUserMapper;

	@Override
	public UserDetails doLogin(String username) {
		...
	}
}

// 策略工厂：把所有项目的具有的策略注入到策略Map中
@Component
@RequiredArgsConstructor	//构造注入
public class LoginStrategyFactory {
	private final Map<String, LoginStrategy> loginStrategyMap;

	public LoginStrategy getInstance(String loginType) {
		return loginStrategyMap.get(loginType);
	}
}

// 调用登录策略进行登录
@Service
@RequiredArgsConstructor
public class UserDetailServiceImpl implements UserDetailsService {
	private final LoginStrategyFactory loginStrategyFactory;

	@Override
	public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
		ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
		HttpServletRequest request = attributes.getRequest();
		String loginType = request.getParameter(AuthConstants.LOGIN_TYPE);
		// 根据请求类型判断登录请求是哪个系统的
	
		// 为了便于扩展（登录方式可能多种），使用策略模式
		LoginStrategy instance = loginStrategyFactory.getInstance(loginType);
		return instance.doLogin(username);
	}
}
~~~

## feign拦截器

使用feign拦截器解决服务调用之间丢失token的情况。

~~~java
@Component
public class FeignInterceptor implements RequestInterceptor {

	@Override
	public void apply(RequestTemplate requestTemplate) {
		ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
		if (ObjectUtil.isNotNull(requestAttributes)) {
			HttpServletRequest request = requestAttributes.getRequest();
			if (ObjectUtil.isNotNull(request)) {
				String authorization = request.getHeader(AuthConstants.AUTH_HEADER_KEY);
				requestTemplate.header(AuthConstants.AUTH_HEADER_KEY, authorization);
				return;
			}
		}
	}
}
~~~



## webSocket

在有`@ServerEndpoint(value = "/chat", configurator = ServerEndpointConfigurator::class)`和`@Component`的类无法在内部进行属性的依赖注入。

报错：kotlin.UninitializedPropertyAccessException: lateinit property stringRedisTemplate has not been initialized

解决方法：

- 方法：在上下文获取你需要的对象

~~~java
@Repository
/**
 * 获取spring容器
 * 当一个类实现了这个接口ApplicationContextAware之后，这个类就可以方便获得ApplicationContext中的所有bean。
 * 换句话说，这个类可以直接获取spring配置文件中所有有引用到的bean对象
 * 前提条件需作为一个普通的bean在spring的配置文件中进行注册 
 */
public class SpringCtxUtils implements ApplicationContextAware {

    private static ApplicationContext applicationContext;

    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
    	SpringCtxUtils.applicationContext = applicationContext;
    }


    public static <T> T getBean(Class<T> type) {
        try {
            return applicationContext.getBean(type);
        } catch (NoUniqueBeanDefinitionException e) {   //出现多个，选第一个
            String beanName = applicationContext.getBeanNamesForType(type)[0];
            return applicationContext.getBean(beanName, type);
        }
    }

    public static <T> T getBean(String beanName, Class<T> type) {
        return applicationContext.getBean(beanName, type);
    }
}

// @ServerEndpoint标注的类中
private StringRedisTemplate stringRedisTemplate = SpringUtils.getBean(StringRedisTemplate.class);
~~~

- 方法2：使用static静态对象

~~~java
private static RedisTemplateUtil redisUtil;
 
@Autowired
public void setRedisTemplateUtil(RedisTemplateUtil redisUtil) {
	WebSocketServer.redisUtil = redisUtil;
}
~~~

## jackson

- 从Json字符串中获取某个字符串变量时出现`lisi != lisi`

	- 原因：用`toString`方法会给原本就是字符串变量的值加上多余的引号
	- 解决：换成`asText`方法

	~~~kotlin
	val rootNode = objectMapper.readTree(json)
			// 不能用toString，会给字符串加上引号变成新的字符串: get(name).toString() ×
			return rootNode.get(kProperty1.name).asText()
	~~~


- `ObjectMapper.writeValueAsString`方法转换的Json默认是会加上引号的字符串，这导致Gson无法直接解析为对象，需要先把引号去掉。

- 报错：class java.util.LinkedHashMap cannot be cast to class com.biluo.chat.pojo.User (java.util.LinkedHashMap is in module java.base of loader 'bootstrap'; com.biluo.chat.pojo.User is in unnamed module of loader 'app')
	- 原因：不明（可能是类型擦除）
	- 解决方法：直接把TypeReference也传入；或传入Class

~~~kotlin
object JsonUtils {
	private val objectMapper = ObjectMapper()
	
	fun <T> toObject(json: String): T {
		return objectMapper.readValue(json, object : TypeReference<T>() {})
	}
}

fun getUser(userJson: String): User {
    //直接返回不会报错，可以正常转换
    //return JsonUtils.toObject(userJson)
    
    //不直接返回，有中间过程则转换失败
    val user: User = JsonUtils.toList<User>(userJson)	//执行到这行就会报上述的错误
    println(user.toString)
    return user
}
~~~

# 框架/工具

## Undertow

Tomcat是Apache基金下的一个轻量级的Servlet容器，支持Servlet和JSP。Tomcat具有Web服务器特有的功能，包括 Tomcat管理和控制平台、安全局管理和Tomcat阀等。Tomcat本身包含了HTTP服务器，因此也可以视作单独的Web服务器。

ApacheHTTP服务器是用C语言实现的HTTP Web服务器。Tomcat是完全免费的，深受开发者的喜爱。

Undertow是Red Hat公司的开源产品, 它完全采用Java语言开发，是一款灵活的高性能Web服务器，支持阻塞IO和非阻塞IO。由于Undertow采用Java语言开发，可以直接嵌入到Java项目中使用。同时， Undertow完全支持Servlet和Web Socket，在高并发情况下表现非常出色。

![undertow架构](assets/undertow-structor.jpg)

> 我们在相同机器配置下压测Tomcat和Undertow，得到的测试结果如下所示：
>
> QPS测试结果对比：
>
> - tomcat：![](C:\Users\797799421\Desktop\笔记\assets\tomcat-qps.jpg)
>
> - undertow
>
>   ![](C:\Users\797799421\Desktop\笔记\assets\undertow-qps.jpg)
>
> 内存占用对比：
>
> - tomcat
>
>   ![](C:\Users\797799421\Desktop\笔记\assets\tomcat-memory.jpg)
>
> - undertow
>
>   ![](C:\Users\797799421\Desktop\笔记\assets\undertow-memory.jpg)
>
> 通过测试发现，在高并发系统中，Tomcat相对来说比较弱。在相同的机器配置下，模拟相等的请求数，Undertow在性能和内存使用方面都是最优的。并且Undertow新版本默认使用持久连接，这将会进一步提高它的并发吞吐能力。所以，如果是高并发的业务系统，Undertow是最佳选择。

SpingBoot中我们既可以使用Tomcat作为Http服务，也可以用Undertow来代替。Undertow在高并发业务场景中，性能优于Tomcat。所以，如果我们的系统是高并发请求，不妨使用一下Undertow，你会发现你的系统性能会得到很大的提升。引入方法如下：

~~~xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
    <exclusions>
        <exclusion>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-tomcat</artifactId>
        </exclusion>
    </exclusions>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-undertow</artifactId>
</dependency>
~~~

## ry-vue

### 替换mb为mp

1. 项目根下的`pom.xml`和`common`模块的`pom.xml`加上mp的依赖。

~~~xml
<!--<mp.version>3.4.2</mp.version>-->

<dependency>
  <groupId>com.baomidou</groupId>
  <artifactId>mybatis-plus-boot-starter</artifactId>
  <version>${mp.version}</version>
</dependency>
~~~

2. `framework`模块下的`MybatisConfig`替换为下面的mp配置类：

~~~java
@Configuration
public class MyBatisPlusConfig {

    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor() {
        MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor();
        //能够添加很多拦截器实现
        mybatisPlusInterceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));
        //乐观锁拦截器
        mybatisPlusInterceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor());
        return mybatisPlusInterceptor;
    }
}
~~~

3. 替换`admin`模块下`application.yml`里mybatis的配置为下面的mp配置：

~~~yaml
mybatis-plus:
  # 搜索指定包别名
  type-aliases-package: com.manage.**.domain
  # 配置mapper的扫描，找到所有的mapper.xml映射文件
  mapper-locations: classpath*:/mapper/**/*Mapper.xml
  # 配置默认的执行器.SIMPLE就是普通执行器;REUSE执行器会重用预处理语句(prepared statements);BATCH执行器将重用语句并执行批量更新
  executor-type: simple
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.slf4j.Slf4jImpl
~~~

4. 可选操作

   - 移除无用的`mybatis-config.xml`配置文件。
   - 移除`pageHelper`分页插件依赖（需要修改`system`等模块的相关方法，改用mp的分页插件）。
   - 不移除`pageHelper`，可以在`BaseController`中新增一个兼容mp分页返回值的方法：

   ~~~java
   protected TableDataInfo getDataTable(IPage<?> page) {
       TableDataInfo rspData = new TableDataInfo();
       rspData.setCode(HttpStatus.SUCCESS);
       rspData.setMsg("查询成功");
       rspData.setRows(page.getRecords());
       rspData.setTotal(page.getTotal());
       return rspData;
   }
   ~~~

### 使用mp的多数据源

参考文章：[SpringBoot+Durid+dynamic-datasource实现多数据源分布式事务_51CTO博客_springboot多数据源原理](https://blog.51cto.com/loveddz/6544321)

1. 项目根下的`pom.xml`和`common`模块的`pom.xml`加上mp的依赖。

~~~xml
<!--<dynamic-datasource.version>3.3.1</dynamic-datasource.version>-->

<dependency>
  <groupId>com.baomidou</groupId>
  <artifactId>dynamic-datasource-spring-boot-starter</artifactId>
  <version>${dynamic-datasource.version}</version>
</dependency>
~~~

2. `admin`模块下的`application-druid.xml`中配置如下内容：

~~~yaml
spring:
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    dynamic:
      druid:
        # 初始连接数
        initialSize: 5
        # 最小连接池数量
        minIdle: 10
        # 最大连接池数量
        maxActive: 20
        # 配置获取连接等待超时的时间
        maxWait: 60000
        # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
        timeBetweenEvictionRunsMillis: 60000
        # 配置一个连接在池中最小生存的时间，单位是毫秒
        minEvictableIdleTimeMillis: 300000
        # 配置一个连接在池中最大生存的时间，单位是毫秒
        maxEvictableIdleTimeMillis: 900000
        # 配置检测连接是否有效
        validationQuery: SELECT 1 FROM DUAL
        testWhileIdle: true
        testOnBorrow: false
        testOnReturn: false
      primary: wf-system
      datasource:
        wf-system:
          url: jdbc:mysql://xxx:3306/wf_system?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
          username: root
          password: xxx
        wf-manage:
          url: jdbc:mysql://xxx:3306/wf_manage?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
          username: root
          password: xxx
~~~

3. `admin`模块的启动类上排除`druid`的自动配置类：`@SpringBootApplication(exclude = {DruidDataSourceAutoConfigure.class})`
4. 移除`framework`模块的`datasource`目录和`DruidConfig`、`DruidProperties`、`DataSourceType`文件，其中`DruidConfig`替换掉相关内容以配置`druid`的浏览器页面。
5. 移除`common`模块下的`DataSource`、`DataSourceType`文件。

> 如果出现使用mp分页插件查询报错，并且内容含有`SELECT COUNT()`，则是因为`pagehelper`依赖 或 `generator`模块 的`jsqlparser`库覆盖了mp的，可以修改mp的版本或排除掉其他依赖的`jsqlparser`库。例如：
>
> ~~~xml
> <dependency>
>   <groupId>com.github.pagehelper</groupId>
>   <artifactId>pagehelper-spring-boot-starter</artifactId>
>   <exclusions>
>     <!--pagehelper的4.5版本会和mp的4.0版本冲突，导致mp的分页插件count查询异常-->
>     <exclusion>
>       <groupId>com.github.jsqlparser</groupId>
>       <artifactId>jsqlparser</artifactId>
>     </exclusion>
>   </exclusions>
> </dependency>
> ~~~
>
> 

## mp

### 扩展mapper

mp的`BaseMapper`只提供了简单的增删改查方法，一些复杂点的操作没有提供，或是在`IService`类中提供。如果想要直接通过mapper类调用这些方法，可以通过扩展`BaseMapper`来使其获取新的功能。

#### insertBatch

例如扩展一个批量插入`insertBatch`的方法。

1. 定义SqlInjector类，扩展功能

~~~java
public class ExpandSqlInjector extends DefaultSqlInjector {
    @Override
    public List<AbstractMethod> getMethodList(Class<?> mapperClass) {
        List<AbstractMethod> methodList = super.getMethodList(mapperClass);
        methodList.add(new InsertBatchMethod());
        methodList.add(new InsertIfNotExistsMethod());
        return methodList;
    }

    /**
     * 批量插入方法
     */
    public static class InsertBatchMethod extends AbstractMethod {
        @Override
        public MappedStatement injectMappedStatement(Class<?> mapperClass, Class<?> modelClass, TableInfo tableInfo) {
            String sql = "<script>INSERT INTO %s (%s) VALUES %s";

            List<String> columnList = new ArrayList<>();
            List<String> propertyList = new ArrayList<>();
            if (tableInfo.havePK() && !AUTO.equals(tableInfo.getIdType())) {
                columnList.add(tableInfo.getKeyColumn());
                propertyList.add(tableInfo.getKeyProperty());
            }
            // getFiledList等方法获取的内容会自动根据@TableField相关配置而改变
            for (TableFieldInfo fieldInfo : tableInfo.getFieldList()) {
                columnList.add(fieldInfo.getColumn());
                propertyList.add(fieldInfo.getProperty());
            }

            String columns = String.join(",", columnList);
            String values = "<foreach collection='list' item='item' separator=','>" +
                    "(#{item." + String.join("},#{item.", propertyList) + "})" +
                    "</foreach></script>";
            String sqlResult = String.format(sql, tableInfo.getTableName(), columns, values);

            SqlSource sqlSource = languageDriver.createSqlSource(configuration, sqlResult, modelClass);
            return getMappedStatement(this::addInsertMappedStatement, mapperClass, "insertBatch", modelClass, tableInfo, sqlSource, "");
        }
    }

    private static MappedStatement getMappedStatement(MappedStatementMethod method, Class<?> mapperClass, String id, Class<?> modelClass, TableInfo tableInfo, SqlSource sqlSource, String prefix) {

        // 根据@TableId注解自动设置KeyGenerator
        KeyGenerator keyGenerator = NoKeyGenerator.INSTANCE; // 默认值
        String keyColumn = null;
        String keyProperty = null;

        // 如果表有主键字段
        if (tableInfo.havePK()) {
            keyColumn = tableInfo.getKeyColumn();
            keyProperty = prefix + tableInfo.getKeyProperty();

            // 根据主键类型设置，INPUT、NONE：NoKeyGenerator，ASSIGN_ID, ASSIGN_UUID等策略，Java层面生成，不需要数据库生成
            if (AUTO.equals(tableInfo.getIdType())) {
                keyGenerator = Jdbc3KeyGenerator.INSTANCE;
            }
        }
        // 这里的keyGenerator与实际sql语句无关，是否插入id取决你构造的sql语句
        return method.accept(mapperClass, modelClass, id, sqlSource, keyGenerator, keyProperty, keyColumn);
    }

    @FunctionalInterface
    public interface MappedStatementMethod {
        MappedStatement accept(Class<?> mapperClass, Class<?> parameterType, String id, SqlSource sqlSource, KeyGenerator keyGenerator, String keyProperty, String keyColumn);
    }
}
~~~

2. 配置SqlInjector：在mp的配置类中（也可以通过yml文件配置）

~~~java
@Bean
public ExpandSqlInjector expandSqlInjector() {
  	return new ExpandSqlInjector();
}
~~~

3. 具体mapper类加上`insertBatch`方法；或定义一个新的`BaseMapper`，让其继承`BaseMapper`（推荐后者，可以统一配置）

> 实际通过前面二步，生成的`BaseMapper`代理类已经有了扩展的方法，这一步了是为了让接口也拥有扩展方法。

~~~java
public interface AppMapper<T> extends BaseMapper<T> {
    /**
     * 批量插入
     * @param list 实体列表
     * @return 插入条数
     */
    int insertBatch(List<T> list);
}
~~~

#### insertIfNotExists

扩展一个不存在则插入`insertIfNotExists`的方法。

##### 单条件

1. ExpandSqlInjector类中添加以下内容

~~~java
public static final String INSERT_IF_NOT_EXISTS = "insertIfNotExists";

/**
 * 如果满足条件的记录不存在才插入
 */
public static class InsertIfNotExistsMethod extends AbstractMethod {
  @Override
  public MappedStatement injectMappedStatement(Class<?> mapperClass, Class<?> modelClass, TableInfo tableInfo) {
    // 动态生成 SQL
    String sql = "<script>INSERT INTO %s (%s) " +
      "SELECT %s FROM dual " +
      "WHERE NOT EXISTS (" +
      "   SELECT 1 FROM %s WHERE ${fieldName} = #{fieldValue}" +
      ")</script>";

    // 1. 插入的字段列表（会自动加上if标签，根据类型添加相关的非空判断，最后一个字段会多个逗号）
    String insertColumns = tableInfo.getAllInsertSqlColumnMaybeIf("entity.");
    insertColumns = SqlScriptUtils.convertTrim(insertColumns, null, null, null, ",");
    // 2. 插入的值（会自动加上if标签，根据类型添加相关的非空判断，最后一个值会多个逗号）
    String insertValues = tableInfo.getAllInsertSqlPropertyMaybeIf("entity.");
    insertValues = SqlScriptUtils.convertTrim(insertValues, null, null, null, ",");

    String tableName = tableInfo.getTableName();
    String sqlResult = String.format(sql, tableName, insertColumns, insertValues, tableName);

    SqlSource sqlSource = languageDriver.createSqlSource(configuration, sqlResult, modelClass);
    return getMappedStatement(this::addInsertMappedStatement, mapperClass, INSERT_IF_NOT_EXISTS, modelClass, tableInfo, sqlSource, "entity.");
  }
}

~~~

2. 拦截mapper方法，对参数进行转换

~~~java
@Intercepts({
        @Signature(type = Executor.class, method = "update", args = {MappedStatement.class, Object.class}),
})
public class ParamsConvertInterceptor implements Interceptor {
    public ParamsConvertInterceptor() {
        log.info("参数转换mp拦截器初始化成功");
    }

    private static final Logger log = LoggerFactory.getLogger(ParamsConvertInterceptor.class);

    /**
     * 拦截方法，在SQL执行前进行处理
     */
    @Override
    public Object intercept(Invocation invocation) throws Throwable {
        Object[] args = invocation.getArgs();
        MappedStatement ms = (MappedStatement) args[0];
        if (ms.getSqlCommandType() != SqlCommandType.INSERT) {
            return invocation.proceed();
        }
        // 获取方法名
        String fullMethodName = ms.getId();
        String methodName = fullMethodName.substring(fullMethodName.lastIndexOf(".") + 1);
        if (!methodName.equals(INSERT_IF_NOT_EXISTS)) {
            return invocation.proceed();
        }
        // 检查参数是否合法
        Object parameter = args[1];
        if (parameter instanceof Map) {
            Map<String, Object> paramMap = (Map<String, Object>) parameter;
            Object fieldName = paramMap.get("fieldName");
            if (fieldName instanceof SFunction) {
                SFunction<?, ?> getter = (SFunction<?, ?>) fieldName;
                String getterMethodName = LambdaUtils.resolve(getter).getImplMethodName();
                String property = PropertyNamer.methodToProperty(getterMethodName);
                String column = StringUtils.camelToUnderline(property);
                paramMap.put("fieldName", column);
            }
        }
        return invocation.proceed();
    }
}
~~~

3. 配置ParamsConvertInterceptor：在mp的配置类中（也可以通过yml文件配置）

~~~java
@Bean
public ParamsConvertInterceptor paramsConvertInterceptor() {
  	return new ParamsConvertInterceptor();
}
~~~

4. AppMapper类里添加以下内容：

~~~java
/**
 * 插入，如果指定字段的字段值已经存在则忽略
 * @param entity 插入的实体类实例
 * @param getter 实体类的getter方法
 * @param value 字段值
 * @return 插入条数
 */
int insertIfNotExists(@Param("entity") T entity, @Param("fieldName") SFunction<T, ?> getter, @Param("fieldValue") Object value);
~~~

##### 多条件

mapper方法使用`Wrapper`作为参数。这种方式实现起来更简单，也能适配单条件。

1. ExpandSqlInjector类中添加以下内容

~~~java
/**
 * 如果满足条件的记录不存在才插入
 */
public static class InsertIfNotExistsMethod extends AbstractMethod {
  @Override
  public MappedStatement injectMappedStatement(Class<?> mapperClass, Class<?> modelClass, TableInfo tableInfo) {
    // 动态生成 SQL
    String sql = "<script>INSERT INTO %s (%s) " +
      "SELECT %s FROM dual " +
      "WHERE NOT EXISTS (" +
      "   SELECT 1 FROM %s ${ew.customSqlSegment}" +
      ")</script>";

    // 1. 插入的字段列表（会自动加上if标签，根据类型添加相关的非空判断，最后一个字段会多个逗号）
    String insertColumns = tableInfo.getAllInsertSqlColumnMaybeIf("entity.");
    insertColumns = SqlScriptUtils.convertTrim(insertColumns, null, null, null, ",");
    // 2. 插入的值（会自动加上if标签，根据类型添加相关的非空判断，最后一个值会多个逗号）
    String insertValues = tableInfo.getAllInsertSqlPropertyMaybeIf("entity.");
    insertValues = SqlScriptUtils.convertTrim(insertValues, null, null, null, ",");

    String tableName = tableInfo.getTableName();
    String sqlResult = String.format(sql, tableName, insertColumns, insertValues, tableName);

    SqlSource sqlSource = languageDriver.createSqlSource(configuration, sqlResult, modelClass);
    return getMappedStatement(this::addInsertMappedStatement, mapperClass, "insertIfNotExists", modelClass, tableInfo, sqlSource, "entity.");
  }
}
~~~

2. AppMapper类里添加以下内容：

~~~java
/**
 * 插入，如果满足指定条件的记录已存在则忽略
 * @param entity 插入的实体类实例
 * @param ew 条件对象
 */
int insertIfNotExists(@Param("entity") T entity, @Param(WRAPPER) Wrapper<T> ew);
~~~



# Idea

## 创建项目卡死

- 方法1：下载archetype-catalog.xml文件 https://repo1.maven.org/maven2/archetype-catalog.xml，打开网址加载完Ctrl+S，**将文件放到maven仓库根目录**
- 方法2：在初始页面创建项目

## 自动重置jdk问题

每次重新加载pom时，Idea都会自动切换模块的默认java语言级别和设置中Java编译器中编译版本为原来的版本，导致运行报错：`java: 警告: 源发行版 11 需要目标发行版 11`

解决方法：

- 修改模块结构中的语言版本和设置中的Java版本，但重新加载pom就会失效
- 在父模块中加上一下配置，永久解决该问题：

~~~xml
<build>
    <plugins>
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-compiler-plugin</artifactId>
            <!--<version>3.1</version>-->
            <configuration>
                <source>1.8</source>
                <target>1.8</target>
            </configuration>
        </plugin>
    </plugins>
</build>
~~~

# 其他

## 绕过备案的方法

解决阿里云等域名需要备案才能设置显性隐性URL的问题，从而可以通过多级域名对应端口访问，而不需要输入端口进行访问。

- 通过静态html跳转（显性URL转发）
	- 比如将域名解析到github pages(或其他静态网页托管平台)
	- 解析到或一个免/已备案服务器上，通过该服务器上的静态页面进行跳转（nginx，tomcat等）
	- 跳转方法：[HTML如何实现网页跳转 | w3cschool笔记](https://www.w3cschool.cn/article/62420882.html#:~:text=方法一：meta 标签 用 meta 标签实现网页跳转，可以设置跳转响应时间，如下例子为在 3 秒后跳转到指定网址。  方法二：JavaScript 设置跳转 JavaScript 设置跳转的方式又有两种，一种是直接跳转，另一种是设定时间跳转。 代码如下：)，并且可以通过js代码（this.location.hostname）获取当前域名来实现跳转到不同端口指向的页面。
- 通过cloudflare的DNS加速来绕过备案（需配置页面规则）
- 使用反向代理：比如nginx，监听80端口，根据不同域名进行代理
	- nginx代理，也可以根据不同URI进行代理
- 使用其他dns服务器解析（隐性URL转发）：比如nat123的DNS解析服务

## vmware

#### 无网络

检查它的`vmware dhcp service`和`vmware nat service`服务是否启动。

#### 无相机

检查它的`VMware USB Arbitration Service`服务是否启动。

若检查出来后，连接按钮时灰色的。找到虚拟机的vmx文件，把`usb.restrictions.defaultAllow`的值改为`TRUE`（没有此行则自己加）

## win10没网

情况：网络适配器中只有Ethernet0（不包括蓝牙）

在Ethernet0属性里ipv4使用DHCP（或其他），但DNS一定要自己分配，例如加一个阿里云的：223.5.5.5