# hive

## derby

### 启动报错

报错：Exception in thread "main" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V

原因：有两个重复的jar包，其实这类错误一般两种思考思路

1. 系统找不到相关jar包
2. 同一类型的 jar 包有不同版本存在，系统无法决定使用哪一个

解决方法：删除`hive/lib`目录下低版本guava的jar包，拷贝hadoop的guava到hive下。

~~~sh
rm -f hive/lib/guava-19.0.jar
 cp ../hadoop/share/hadoop/common/lib/guava-27.0-jre.jar lib/
~~~

## hiveserver2

### 插入数据失败

报错： FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.tez.TezTask

原因：Tez时检查到用过多内存而被NodeManager杀死进程问题，这种问题是从机上运行的Container试图使用过多的内存，而被NodeManager kill掉了。

解决方法：

- 方法1：修改yarn-site.xml，关掉虚拟内存检查

	> centos7和JDK的内存分配存在矛盾，centos为java运行留了较大的虚拟内存，但JDK却无法使用这块内存，只能使用剩余虚拟内存，导致容易出现oom。建议关掉虚拟内存检查。

~~~xml
<property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
</property>
~~~

- 根据机器大小合理修改map和reduce的内存分配。

# 补充

## hive

### 去重的方法

- 方法1：使用distinct关键字去重，它会根据后面字段进行整体去重。

~~~sql
select distinct 字段1, 字段2... from table;
~~~



- 方法2：使用group by 去重，想要根据哪些字段整体去重，后面就跟上哪些字段

> 原理：多个字段分组相当于把这多个字段当作整体，不同的整体分组后返回一条记录

~~~sql
select 字段1, 字段2... from table group by 字段1, 字段2...;
~~~



- 方法3：使用窗口函数，将每个整体作为分区，在分区内进行编号，取编号为1即可

~~~sql
select 字段1, 字段2... from (
    Select 字段1, 字段2..., row_number() over (partition by 字段1, 字段2...) rn from table
) tmp where rn = 1;
~~~

